arxiv_id,title,authors,abstract,categories,published_date,pdf_url
2510.08572v1,BLAZER: Bootstrapping LLM-based Manipulation Agents with Zero-Shot Data   Generation,"['Rocktim Jyoti Das', 'Harsh Singh', 'Diana Turmakhan', 'Muhammad Abdullah Sohail', 'Mingfei Han', 'Preslav Nakov', 'Fabio Pizzati', 'Ivan Laptev']","Scaling data and models has played a pivotal role in the remarkable progress of computer vision and language. Inspired by these domains, recent efforts in robotics have similarly focused on scaling both data and model size to develop more generalizable and robust policies. However, unlike vision and language, robotics lacks access to internet-scale demonstrations across diverse robotic tasks and environments. As a result, the scale of existing datasets typically suffers from the need for manual data collection and curation. To address this problem, here we propose BLAZER, a framework that learns manipulation policies from automatically generated training data. We build on the zero-shot capabilities of LLM planners and automatically generate demonstrations for diverse manipulation tasks in simulation. Successful examples are then used to finetune an LLM and to improve its planning capabilities without human supervision. Notably, while BLAZER training requires access to the simulator's state, we demonstrate direct transfer of acquired skills to sensor-based manipulation. Through extensive experiments, we show BLAZER to significantly improve zero-shot manipulation in both simulated and real environments. Moreover, BLAZER improves on tasks outside of its training pool and enables downscaling of LLM models. Our code and data will be made publicly available on the project page.","['cs.RO', 'cs.AI', 'cs.LG']",2025-10-09T17:59:58Z,.data/arxiv_pdfs/2510.08572v1.pdf
