label,prov,caption,content
table,"[{'page_no': 7, 'bbox': {'l': 70.734375, 't': 651.8907928466797, 'r': 540.53173828125, 'b': 402.2509460449219, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0.0, 0.0]}]","['Table 1: Grounding element accuracy on ScreenSpot-Pro . The results of models marked with † are adopted from Wu et al. (2025a). Best results per column within each comparable model group are shown in bold . Note that results in the first two groups are not directly comparable to ours, either because the models are closed-source (weights/architectures unavailable) or because their training data and underlying base models are unclear or incomparable. We nevertheless include these numbers for reference.']","| Model                                          | Dev                                            | Creative                                       | CAD                                            | Scientific                                     | Office                                         | OS                                             | Avg                                            |
|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|
| GPT-4o †                                       | 0.7                                            | 0.6                                            | 1.5                                            | 1.2                                            | 0.9                                            | 0.0                                            | 0.8                                            |
| Claude Compute †                               | 12.6                                           | 16.8                                           | 11.9                                           | 25.8                                           | 26.9                                           | 8.1                                            | 17.1                                           |
| Qwen2-VL-7B †                                  | 1.3                                            | 0.9                                            | 0.4                                            | 3.5                                            | 3.0                                            | 0.5                                            | 1.6                                            |
| SeeClick-9.6B †                                | 0.3                                            | 0.6                                            | 1.9                                            | 2.0                                            | 0.9                                            | 1.5                                            | 1.1                                            |
| OS-Atlas-7B †                                  | 17.7                                           | 17.9                                           | 10.3                                           | 24.4                                           | 27.4                                           | 16.8                                           | 18.9                                           |
| Aguvis-7B †                                    | 16.1                                           | 21.4                                           | 13.8                                           | 34.6                                           | 34.3                                           | 19.4                                           | 22.9                                           |
| UGround-V1-7B                                  | 28.1                                           | 31.7                                           | 14.6                                           | 39.0                                           | 49.6                                           | 24.5                                           | 31.1                                           |
| UI-TARS-7B                                     | 36.1                                           | 32.8                                           | 18.0                                           | 50.0                                           | 53.5                                           | 24.5                                           | 35.7                                           |
| GUI-Actor-7B + Verifier †                      | 38.8                                           | 40.5                                           | 37.2                                           | 44.5                                           | 64.8                                           | 43.9                                           | 44.2                                           |
| Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework |
| LLaVA-NeXT + LLaVA PE                          | 23.1                                           | 25.5                                           | 12.6                                           | 35.4                                           | 43.8                                           | 20.5                                           | 26.8                                           |
| LLaVA-NeXT + MRoPE                             | 26.8                                           | 29.4                                           | 13.6                                           | 36.5                                           | 47.5                                           | 21.2                                           | 29.2                                           |
| LLaVA-NeXT + I-MROPE                           | 27.1                                           | 29.8                                           | 13.8                                           | 36.6                                           | 47.8                                           | 21.5                                           | 29.4                                           |
| LLaVA-NeXT + I-MROPE + RULER                   | 28.2                                           | 32.1                                           | 15.3                                           | 40.5                                           | 51.6                                           | 24.8                                           | 32.1                                           |
| Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     |
| Qwen2.5-VL                                     | 31.4                                           | 34.2                                           | 17.1                                           | 42.8                                           | 54.0                                           | 28.3                                           | 34.6                                           |
| Qwen2.5-VL + RULER                             | 34.2                                           | 36.5                                           | 21.1                                           | 43.9                                           | 55.4                                           | 32.0                                           | 37.2                                           |"
table,"[{'page_no': 8, 'bbox': {'l': 71.036865234375, 't': 684.2841110229492, 'r': 540.5086669921875, 'b': 421.88787841796875, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0.0, 0.0]}]",['Table 2: Grounding element accuracy on ScreenSpot . The results of models marked with † are adopted from Wu et al. (2025a). Best results per column within each group are shown in bold .'],"|                                                | M-Text                                         | M-Icon                                         | D-Text                                         | D-Icon                                         | W-Text                                         | W-Icon                                         | Avg                                            |
|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|
| GPT-4 †                                        | 22.6                                           | 24.5                                           | 20.2                                           | 11.8                                           | 9.2                                            | 8.8                                            | 16.2                                           |
| GPT-4o †                                       | 20.2                                           | 24.9                                           | 21.1                                           | 23.6                                           | 12.2                                           | 7.8                                            | 18.3                                           |
| Claude Computer Use †                          | -                                              | -                                              | -                                              | -                                              | -                                              | -                                              | 83.0                                           |
| Gemini 2.0 †                                   | -                                              | -                                              | -                                              | -                                              | -                                              | -                                              | 84.0                                           |
| Qwen2-VL-7B †                                  | 75.5                                           | 60.7                                           | 76.3                                           | 54.3                                           | 35.2                                           | 25.7                                           | 55.3                                           |
| SeeClick-9.6B †                                | 78.0                                           | 52.0                                           | 72.2                                           | 30.0                                           | 55.7                                           | 32.5                                           | 53.4                                           |
| OS-Atlas-7B †                                  | 93.0                                           | 72.9                                           | 91.8                                           | 62.9                                           | 90.9                                           | 74.3                                           | 82.5                                           |
| Aguvis-7B                                      | 95.6 †                                         | 77.7                                           | 93.8                                           | 67.1                                           | 88.3                                           | 75.2                                           | 84.4                                           |
| UGround-v1-7B                                  | 93.0                                           | 79.9                                           | 93.8                                           | 76.4                                           | 90.9                                           | 84.0                                           | 86.3                                           |
| UI-TARS-7B                                     | 94.5                                           | 85.2                                           | 95.9                                           | 85.7                                           | 90.0                                           | 83.5                                           | 89.5                                           |
| GUI-Actor-7B + Verifier †                      | 96.0                                           | 83.0                                           | 93.8                                           | 82.1                                           | 92.2                                           | 87.4                                           | 89.7                                           |
| Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework |
| LLaVA-NeXT + LLaVA PE                          | 88.9                                           | 74.2                                           | 88.3                                           | 70.2                                           | 85.7                                           | 75.4                                           | 80.5                                           |
| LLaVA-NeXT + MRoPE                             | 90.0                                           | 76.2                                           | 90.2                                           | 72.7                                           | 88.3                                           | 77.5                                           | 82.5                                           |
| LLaVA-NeXT + I-MROPE                           | 90.5                                           | 76.9                                           | 90.9                                           | 73.4                                           | 88.5                                           | 77.7                                           | 83.0                                           |
| LLaVA-NeXT + I-MROPE + RULER                   | 91.4                                           | 77.0                                           | 91.5                                           | 73.2                                           | 89.5                                           | 77.2                                           | 83.3                                           |
| Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     |
| Qwen2.5-VL                                     | 93.4                                           | 80.5                                           | 94.6                                           | 76.4                                           | 91.1                                           | 84.6                                           | 86.8                                           |
| Qwen2.5-VL + RULER                             | 94.2                                           | 84.1                                           | 93.6                                           | 76.5                                           | 92.4                                           | 85.3                                           | 87.7                                           |"
table,"[{'page_no': 9, 'bbox': {'l': 70.86250305175781, 't': 684.0099487304688, 'r': 540.7288818359375, 'b': 470.039306640625, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0.0, 0.0]}]",['Table 3: Grounding element accuracy on ScreenSpot-V2 . The results of models marked with † are adopted from Wu et al. (2025a). Best results per column within each group are shown in bold .'],"|                                                | M-Text                                         | M-Icon                                         | D-Text                                         | D-Icon                                         | W-Text                                         | W-Icon                                         | Avg                                            |
|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|:-----------------------------------------------|
| GPT-4o + OmniParser-v2 †                       | 95.5                                           | 74.6                                           | 92.3                                           | 60.9                                           | 88.0                                           | 59.6                                           | 80.7                                           |
| SeeClick-9.6B †                                | 78.4                                           | 50.7                                           | 70.1                                           | 29.3                                           | 55.2                                           | 32.5                                           | 55.1                                           |
| OS-Atlas-7B †                                  | 95.2                                           | 75.8                                           | 90.7                                           | 63.6                                           | 90.6                                           | 77.3                                           | 84.1                                           |
| Aguvis-7B †                                    | 95.5                                           | 77.3                                           | 95.4                                           | 77.9                                           | 91.0                                           | 72.4                                           | 86.0                                           |
| UGround-V1-7B                                  | 95.0                                           | 83.3                                           | 95.0                                           | 77.8                                           | 92.1                                           | 77.2                                           | 87.6                                           |
| UI-TARS-7B                                     | 96.9                                           | 89.1                                           | 95.4                                           | 85.0                                           | 93.6                                           | 85.2                                           | 91.6                                           |
| GUI-Actor-7B + Verifier †                      | 97.2                                           | 84.8                                           | 94.3                                           | 85.0                                           | 94.0                                           | 85.2                                           | 90.9                                           |
| Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework | Trained From Scratch with LLaVA-NeXT Framework |
| LLaVA-NeXT + LLaVA PE                          | 92.4                                           | 78.8                                           | 90.1                                           | 75.3                                           | 87.9                                           | 74.1                                           | 83.1                                           |
| LLaVA-NeXT + MRoPE                             | 93.2                                           | 79.1                                           | 90.8                                           | 76.6                                           | 88.0                                           | 76.3                                           | 84.0                                           |
| LLaVA-NeXT + I-MROPE                           | 93.4                                           | 80.0                                           | 91.3                                           | 77.5                                           | 88.1                                           | 76.7                                           | 84.5                                           |
| LLaVA-NeXT + I-MROPE + RULER                   | 95.0                                           | 82.7                                           | 90.3                                           | 79.8                                           | 88.6                                           | 77.1                                           | 85.6                                           |
| Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     | Finetuning                                     |
| Qwen2.5-VL                                     | 95.6                                           | 85.2                                           | 95.2                                           | 80.8                                           | 92.5                                           | 79.9                                           | 88.2                                           |
| Qwen2.5-VL + RULER                             | 96.2                                           | 87.0                                           | 95.3                                           | 80.5                                           | 93.2                                           | 81.6                                           | 89.0                                           |"
